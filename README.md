# ğŸ¤– Chatbot Local RAG com Groq Cloud + Streamlit

Este projeto implementa um chatbot inteligente utilizando Groq Cloud para geraÃ§Ã£o de respostas, com o modelo principal "llama-3.1-8b-instant" e fallback em "allam-2-7b". O frontend Ã© construÃ­do em Streamlit e a lÃ³gica de respostas Ã© limitada exclusivamente aos arquivos fornecidos pelo usuÃ¡rio (RAG local). As variÃ¡veis de ambiente sÃ£o carregadas via arquivo .env.

O comportamento Ã© semelhante ao Google NotebookLM, respondendo somente com base nos documentos anexados. Caso os arquivos nÃ£o contenham informaÃ§Ãµes suficientes, o chatbot responde:  
"NÃ£o hÃ¡ dados suficientes nos arquivos fornecidos para responder isso."

---

## ğŸ“‚ Estrutura do Projeto

```mermaid
graph TD
    A[project/] --> B[data/]
    B --> B1[arquivo1.txt]
    B --> B2[arquivo2.md]
    A --> C[app.py]
    A --> D[.env]
    A --> E[README.md]
    A --> F[requirements.txt]
```

---

## âš™ï¸ InstalaÃ§Ã£o e Setup

1. Crie um ambiente virtual (opcional, porÃ©m recomendado):

```powershell
python -m venv venv
venv\Scripts\activate
```

2. Instale as dependÃªncias:

```powershell
pip install streamlit groq python-dotenv
```

Ou:

```powershell
pip install -r requirements.txt
```

3. Crie o arquivo .env na raiz do projeto contendo:

```ini
GROQ_API_KEY=sua_chave_aqui
```

---

## â–¶ï¸ Executar o projeto

```powershell
streamlit run app.py
```

A aplicaÃ§Ã£o rodarÃ¡ em: http://localhost:8501

---

## ğŸ§  Como funciona a busca local (RAG simples)

- O chatbot nÃ£o usa internet.  
- Ele sÃ³ responde com base no conteÃºdo da pasta "data".  
- Os arquivos sÃ£o lidos e divididos em pequenos trechos (chunks).  
- Uma busca por similaridade textual encontra os trechos mais relevantes.  
- Somente esses trechos sÃ£o enviados ao modelo Groq.  
- Se nenhum trecho for relevante, o chatbot informa que nÃ£o hÃ¡ dados suficientes.

Esse comportamento evita alucinaÃ§Ãµes e mantÃ©m as respostas alinhadas aos documentos.

---

## ğŸ“Œ Principais funÃ§Ãµes

indexar_documentos: lÃª os arquivos da pasta data e gera chunks.  
buscar_contexto: retorna os trechos mais relevantes com base na pergunta.  
gerar_resposta: usa o contexto encontrado para construir o prompt enviado ao Groq Cloud.

HÃ¡ fallback automÃ¡tico caso o modelo principal falhe.

---

## ğŸ–¥ï¸ Interface Streamlit

A interface fornece:  
- Caixa de chat  
- HistÃ³rico de mensagens  
- Layout estilo mensagens do ChatGPT  
- IntegraÃ§Ã£o com Groq Cloud  
- LÃ³gica de RAG local para respostas

---

## ğŸš¨ Tratamento de erros

- Se a variÃ¡vel GROQ_API_KEY nÃ£o existir â†’ erro claro no inÃ­cio  
- Se o modelo principal falhar â†’ fallback automÃ¡tico  
- Se nÃ£o houver trechos relevantes â†’ resposta "nÃ£o hÃ¡ dados suficientes"  
- Se ambos os modelos falharem â†’ mensagem de fallback padrÃ£o  

---

## ğŸ“„ LicenÃ§a

CÃ³digo livre para uso, modificaÃ§Ã£o e distribuiÃ§Ã£o.

